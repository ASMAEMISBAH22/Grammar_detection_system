{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1aXAMzHXMAKxJxFWXGW2wxiFLcyjCdpWf","authorship_tag":"ABX9TyPCI5QPnpoNQQ3HlS+LFCmn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9dadb83623e44ccb86dc317bdd11e227":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7d6cec3ad5a452f891c6f8e40da8b1b","IPY_MODEL_ad13d4d34e8d43479d3b2c2fc19a4fa6","IPY_MODEL_f145e8b451c4405ea6b29864fb49848f"],"layout":"IPY_MODEL_4a9bde5e5a754d7dac9cf9f787f41e2a"}},"a7d6cec3ad5a452f891c6f8e40da8b1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7b5db8a51f44e7388f5285a2bf8db21","placeholder":"​","style":"IPY_MODEL_968c13365f79429e9d6ae0c2c1efa135","value":"Generating train split: "}},"ad13d4d34e8d43479d3b2c2fc19a4fa6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae9572ae7546463881abbb7a751e499a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1f9a87d3cf34a2abdf00cd82aa8104b","value":1}},"f145e8b451c4405ea6b29864fb49848f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b05302bb78d489b81d1d5e8aa9e1ff7","placeholder":"​","style":"IPY_MODEL_6707d8ba699e46e2bff4a8b150a9f992","value":" 38959/0 [00:01&lt;00:00, 36035.27 examples/s]"}},"4a9bde5e5a754d7dac9cf9f787f41e2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7b5db8a51f44e7388f5285a2bf8db21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"968c13365f79429e9d6ae0c2c1efa135":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae9572ae7546463881abbb7a751e499a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e1f9a87d3cf34a2abdf00cd82aa8104b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b05302bb78d489b81d1d5e8aa9e1ff7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6707d8ba699e46e2bff4a8b150a9f992":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91648a7f34ec4850afd605b9bb622357":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_288242af38c34183956245833bb0ee75","IPY_MODEL_accebd4bf0e649d7afe64916824b2123","IPY_MODEL_d884873faff048f39b43ac1a1d49facb"],"layout":"IPY_MODEL_ccf7c3c349cd48289f4c5fe824c3fe5b"}},"288242af38c34183956245833bb0ee75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7af02c366048467a980a673562438d97","placeholder":"​","style":"IPY_MODEL_20d3f52bb3c44265830347b0a40a66c6","value":"Generating train split: "}},"accebd4bf0e649d7afe64916824b2123":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb0d211856f4bc08b50b8c4c8ce3fd3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_497ddf8add594fe5846b6ed1c6958289","value":1}},"d884873faff048f39b43ac1a1d49facb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_216edd278d4e44fbb5f23c26017db74e","placeholder":"​","style":"IPY_MODEL_d2e099d24ff64ca296593df2ef7bb48a","value":" 4870/0 [00:00&lt;00:00, 79990.99 examples/s]"}},"ccf7c3c349cd48289f4c5fe824c3fe5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7af02c366048467a980a673562438d97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20d3f52bb3c44265830347b0a40a66c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fb0d211856f4bc08b50b8c4c8ce3fd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"497ddf8add594fe5846b6ed1c6958289":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"216edd278d4e44fbb5f23c26017db74e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2e099d24ff64ca296593df2ef7bb48a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a4fe5f3274f4f14b51374c973f18d15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c3b7cf98ad0411aa6cbf1f1f7f7ce13","IPY_MODEL_8f0b879c755b4a79b0ee55d0a293d3b2","IPY_MODEL_1f7f3edbb32c4536932d85ab4d2c2f5d"],"layout":"IPY_MODEL_b0243f94eedc4aa28f9ba165fe6846e8"}},"2c3b7cf98ad0411aa6cbf1f1f7f7ce13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d578bd993e0c43408fea2b44d4d6b118","placeholder":"​","style":"IPY_MODEL_65c32bec6b17494195ad2b193725d16d","value":"Generating train split: "}},"8f0b879c755b4a79b0ee55d0a293d3b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_adf91c867c4d432c80f11d1681686904","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88b6036e91cf4552b384bd34fa3dd6a6","value":1}},"1f7f3edbb32c4536932d85ab4d2c2f5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ced564f8d12f4792b08d010dc565a2f4","placeholder":"​","style":"IPY_MODEL_1c1ab5f03a744d179b29200541f6ab30","value":" 4870/0 [00:00&lt;00:00, 79058.48 examples/s]"}},"b0243f94eedc4aa28f9ba165fe6846e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d578bd993e0c43408fea2b44d4d6b118":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65c32bec6b17494195ad2b193725d16d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adf91c867c4d432c80f11d1681686904":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"88b6036e91cf4552b384bd34fa3dd6a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ced564f8d12f4792b08d010dc565a2f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c1ab5f03a744d179b29200541f6ab30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9661b90c69c44c3383e61ae755dfdd0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce01536cb5d34680b49ac709600a6852","IPY_MODEL_409fe6129a734d7e89e9e0b061bf8982","IPY_MODEL_1009c0b78ac54bf1a5df560f7de42223"],"layout":"IPY_MODEL_b70f5eb04172400ca73ddc927ad3b2e4"}},"ce01536cb5d34680b49ac709600a6852":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b24cd90855aa4d5186ea798bc1ecb9e4","placeholder":"​","style":"IPY_MODEL_bec98a7d552f408a94c03d558d08eec5","value":"Map: 100%"}},"409fe6129a734d7e89e9e0b061bf8982":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_971d519c2894490892e679cacbaf1904","max":38959,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62b89fe38c664cf59d9e67ec60b9374c","value":38959}},"1009c0b78ac54bf1a5df560f7de42223":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52b7d634d1934796b4e38dae44377362","placeholder":"​","style":"IPY_MODEL_fa108a51ebe34c32b70d2164e89981d3","value":" 38959/38959 [00:28&lt;00:00, 1518.43 examples/s]"}},"b70f5eb04172400ca73ddc927ad3b2e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b24cd90855aa4d5186ea798bc1ecb9e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec98a7d552f408a94c03d558d08eec5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"971d519c2894490892e679cacbaf1904":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62b89fe38c664cf59d9e67ec60b9374c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52b7d634d1934796b4e38dae44377362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa108a51ebe34c32b70d2164e89981d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e802eb56f094da6a95e51864d7db8f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8919497a034f4977a662ac4df3081556","IPY_MODEL_7f41101734ed40858b3e116d977e2e72","IPY_MODEL_67a24ec7339141fc8a4b1fb3f829c459"],"layout":"IPY_MODEL_278bdec00a21413daf6f9f8b22a3d3c2"}},"8919497a034f4977a662ac4df3081556":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccbf7c032fcc4511bbddd65f75eeb394","placeholder":"​","style":"IPY_MODEL_328699bf2d5b494da6fdda8fdc83333c","value":"Map: 100%"}},"7f41101734ed40858b3e116d977e2e72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb429b7acaae4a04b96f228efa107d89","max":4870,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbe7eec26a944154b22186f0643bff94","value":4870}},"67a24ec7339141fc8a4b1fb3f829c459":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ead837b3b584b3bab7ae06efa6246d7","placeholder":"​","style":"IPY_MODEL_f289316880824b67bdf5576362efc08e","value":" 4870/4870 [00:04&lt;00:00, 994.81 examples/s]"}},"278bdec00a21413daf6f9f8b22a3d3c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccbf7c032fcc4511bbddd65f75eeb394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"328699bf2d5b494da6fdda8fdc83333c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb429b7acaae4a04b96f228efa107d89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbe7eec26a944154b22186f0643bff94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ead837b3b584b3bab7ae06efa6246d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f289316880824b67bdf5576362efc08e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58e4359efeea4c37afd3322d16083e59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee23464a281544ab8fa0311b8f1fe0c3","IPY_MODEL_9b86bcaa84224f13bff9ee2706cd58fa","IPY_MODEL_8d1dfc90bb244d26914a8e6c8c111210"],"layout":"IPY_MODEL_95c2bace319c42458b39787229dff54b"}},"ee23464a281544ab8fa0311b8f1fe0c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac005a8c7ba445f2afa940d1da774561","placeholder":"​","style":"IPY_MODEL_40267becea0d4ef28d814fb1080e395d","value":"Map: 100%"}},"9b86bcaa84224f13bff9ee2706cd58fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0dacdbed9a74686828fdbaafda0e880","max":4870,"min":0,"orientation":"horizontal","style":"IPY_MODEL_840c3a6db6ea446093c1098b06c81cdf","value":4870}},"8d1dfc90bb244d26914a8e6c8c111210":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f15b09f57042412e868cbff222814502","placeholder":"​","style":"IPY_MODEL_115ab44c6912432c869ea5e9e369e376","value":" 4870/4870 [00:03&lt;00:00, 1502.00 examples/s]"}},"95c2bace319c42458b39787229dff54b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac005a8c7ba445f2afa940d1da774561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40267becea0d4ef28d814fb1080e395d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0dacdbed9a74686828fdbaafda0e880":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"840c3a6db6ea446093c1098b06c81cdf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f15b09f57042412e868cbff222814502":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"115ab44c6912432c869ea5e9e369e376":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -U transformers accelerate datasets peft\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yQLTzN4MxBu","executionInfo":{"status":"ok","timestamp":1764514100854,"user_tz":-60,"elapsed":10441,"user":{"displayName":"Asmae Misbah","userId":"03840885929360177687"}},"outputId":"c8ed6c33-365a-42bb-fe89-e6acef045d8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","base_path = \"/content/drive/MyDrive/GrammarCorrectionProject/data/processed/\"\n","\n","train_path = base_path + \"train_en.csv\"\n","valid_path = base_path + \"valid_en.csv\"\n","test_path  = base_path + \"test_en.csv\"\n","\n","train_dataset = load_dataset(\"csv\", data_files=train_path)[\"train\"]\n","valid_dataset = load_dataset(\"csv\", data_files=valid_path)[\"train\"]\n","test_dataset  = load_dataset(\"csv\", data_files=test_path)[\"train\"]\n","\n","train_dataset, valid_dataset, test_dataset\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332,"referenced_widgets":["9dadb83623e44ccb86dc317bdd11e227","a7d6cec3ad5a452f891c6f8e40da8b1b","ad13d4d34e8d43479d3b2c2fc19a4fa6","f145e8b451c4405ea6b29864fb49848f","4a9bde5e5a754d7dac9cf9f787f41e2a","f7b5db8a51f44e7388f5285a2bf8db21","968c13365f79429e9d6ae0c2c1efa135","ae9572ae7546463881abbb7a751e499a","e1f9a87d3cf34a2abdf00cd82aa8104b","3b05302bb78d489b81d1d5e8aa9e1ff7","6707d8ba699e46e2bff4a8b150a9f992","91648a7f34ec4850afd605b9bb622357","288242af38c34183956245833bb0ee75","accebd4bf0e649d7afe64916824b2123","d884873faff048f39b43ac1a1d49facb","ccf7c3c349cd48289f4c5fe824c3fe5b","7af02c366048467a980a673562438d97","20d3f52bb3c44265830347b0a40a66c6","2fb0d211856f4bc08b50b8c4c8ce3fd3","497ddf8add594fe5846b6ed1c6958289","216edd278d4e44fbb5f23c26017db74e","d2e099d24ff64ca296593df2ef7bb48a","3a4fe5f3274f4f14b51374c973f18d15","2c3b7cf98ad0411aa6cbf1f1f7f7ce13","8f0b879c755b4a79b0ee55d0a293d3b2","1f7f3edbb32c4536932d85ab4d2c2f5d","b0243f94eedc4aa28f9ba165fe6846e8","d578bd993e0c43408fea2b44d4d6b118","65c32bec6b17494195ad2b193725d16d","adf91c867c4d432c80f11d1681686904","88b6036e91cf4552b384bd34fa3dd6a6","ced564f8d12f4792b08d010dc565a2f4","1c1ab5f03a744d179b29200541f6ab30"]},"id":"_j4fd9i2NJeo","executionInfo":{"status":"ok","timestamp":1764622357202,"user_tz":-60,"elapsed":12508,"user":{"displayName":"Asmae Misbah","userId":"03840885929360177687"}},"outputId":"329814f7-a5e2-4aeb-85d5-4de680656f24"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dadb83623e44ccb86dc317bdd11e227"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91648a7f34ec4850afd605b9bb622357"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a4fe5f3274f4f14b51374c973f18d15"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["(Dataset({\n","     features: ['source', 'target'],\n","     num_rows: 38959\n"," }),\n"," Dataset({\n","     features: ['source', 'target'],\n","     num_rows: 4870\n"," }),\n"," Dataset({\n","     features: ['source', 'target'],\n","     num_rows: 4870\n"," }))"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["def preprocess(batch):\n","    # Add prefix\n","    inputs = [\"gec: \" + s for s in batch[\"source\"]]\n","    outputs = batch[\"target\"]\n","\n","    # Tokenize inputs\n","    model_inputs = tokenizer(\n","        inputs,\n","        max_length=128,\n","        truncation=True,\n","        padding=\"max_length\"\n","    )\n","\n","    # Tokenize labels\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            outputs,\n","            max_length=128,\n","            truncation=True,\n","            padding=\"max_length\"\n","        )[\"input_ids\"]\n","\n","    # Mask padding tokens\n","    labels = [\n","        [-100 if tok == tokenizer.pad_token_id else tok for tok in seq]\n","        for seq in labels\n","    ]\n","\n","    model_inputs[\"labels\"] = labels\n","    return model_inputs\n"],"metadata":{"id":"_XFCKupDsrXH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = train_dataset.map(\n","    preprocess,\n","    batched=True,\n","    remove_columns=train_dataset.column_names\n",")\n","\n","valid_dataset = valid_dataset.map(\n","    preprocess,\n","    batched=True,\n","    remove_columns=valid_dataset.column_names\n",")\n","\n","test_dataset = test_dataset.map(\n","    preprocess,\n","    batched=True,\n","    remove_columns=test_dataset.column_names\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169,"referenced_widgets":["9661b90c69c44c3383e61ae755dfdd0b","ce01536cb5d34680b49ac709600a6852","409fe6129a734d7e89e9e0b061bf8982","1009c0b78ac54bf1a5df560f7de42223","b70f5eb04172400ca73ddc927ad3b2e4","b24cd90855aa4d5186ea798bc1ecb9e4","bec98a7d552f408a94c03d558d08eec5","971d519c2894490892e679cacbaf1904","62b89fe38c664cf59d9e67ec60b9374c","52b7d634d1934796b4e38dae44377362","fa108a51ebe34c32b70d2164e89981d3","9e802eb56f094da6a95e51864d7db8f9","8919497a034f4977a662ac4df3081556","7f41101734ed40858b3e116d977e2e72","67a24ec7339141fc8a4b1fb3f829c459","278bdec00a21413daf6f9f8b22a3d3c2","ccbf7c032fcc4511bbddd65f75eeb394","328699bf2d5b494da6fdda8fdc83333c","cb429b7acaae4a04b96f228efa107d89","cbe7eec26a944154b22186f0643bff94","3ead837b3b584b3bab7ae06efa6246d7","f289316880824b67bdf5576362efc08e","58e4359efeea4c37afd3322d16083e59","ee23464a281544ab8fa0311b8f1fe0c3","9b86bcaa84224f13bff9ee2706cd58fa","8d1dfc90bb244d26914a8e6c8c111210","95c2bace319c42458b39787229dff54b","ac005a8c7ba445f2afa940d1da774561","40267becea0d4ef28d814fb1080e395d","d0dacdbed9a74686828fdbaafda0e880","840c3a6db6ea446093c1098b06c81cdf","f15b09f57042412e868cbff222814502","115ab44c6912432c869ea5e9e369e376"]},"id":"Fie6yoANsaNv","executionInfo":{"status":"ok","timestamp":1764622556959,"user_tz":-60,"elapsed":36932,"user":{"displayName":"Asmae Misbah","userId":"03840885929360177687"}},"outputId":"49d982bc-bd5b-42db-ede5-5f0a13393f9b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/38959 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9661b90c69c44c3383e61ae755dfdd0b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4118: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4870 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e802eb56f094da6a95e51864d7db8f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4870 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58e4359efeea4c37afd3322d16083e59"}},"metadata":{}}]},{"cell_type":"code","source":["train_dataset.set_format(type=\"torch\")\n","valid_dataset.set_format(type=\"torch\")\n","test_dataset.set_format(type=\"torch\")\n"],"metadata":{"id":"KLXaibyZtGPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import T5TokenizerFast, T5ForConditionalGeneration\n","\n","model_name = \"gotutiyan/gec-t5-large-clang8\"\n","tokenizer = T5TokenizerFast.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","model.config.pad_token_id = tokenizer.pad_token_id\n","model.config.use_cache = False\n"],"metadata":{"id":"46mMRJtiNQrg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uMzE5wxytCap","executionInfo":{"status":"ok","timestamp":1764622640544,"user_tz":-60,"elapsed":46,"user":{"displayName":"Asmae Misbah","userId":"03840885929360177687"}},"outputId":"9797dba7-3489-44cc-9e69-01e4e74d8e55"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([  873,    75,    10,  2210, 19519,    10,  3790,    19,    29,    31,\n","            17,   786,    19,   255,     1,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'labels': tensor([3790,   19,   29,   31,   17,  786,    6,   19,  255,   58,    1, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","         -100, -100, -100, -100, -100, -100, -100, -100])}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./gec_en_finetuned\",\n","    logging_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    eval_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    gradient_accumulation_steps=8,\n","    num_train_epochs=4,\n","    weight_decay=0.01,\n","    fp16=True,\n","    report_to=\"none\",   # disable wandb\n",")\n","\n","model.gradient_checkpointing_enable()\n"],"metadata":{"id":"H5huMEg8tg2E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":482},"id":"RzsGlg1LtjKi","executionInfo":{"status":"error","timestamp":1764623106460,"user_tz":-60,"elapsed":65,"user":{"displayName":"Asmae Misbah","userId":"03840885929360177687"}},"outputId":"b358f922-4fab-4800-bbb7-bcabb56a52ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1169413603.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 3268 has 14.73 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, and 30.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1169413603.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer = Trainer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quantization_method\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mQuantizationMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBITS_AND_BYTES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         ):\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    908\u001b[0m             )\n\u001b[1;32m    909\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4341\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4342\u001b[0m                 )\n\u001b[0;32m-> 4343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1355\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m                     )\n\u001b[0;32m-> 1357\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1358\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 3268 has 14.73 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, and 30.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"markdown","source":["we are hitting OOM before training even starts because:\n","\n","✔ T5-Large + 15GB GPU = too large to load in full precision\n","\n","And your GPU already has no free memory left (4MB free).\n","So just loading the model triggers OOM.\n"],"metadata":{"id":"t_kaorRIxW9R"}},{"cell_type":"markdown","source":["The ONLY solution that works on a 15GB GPU:\n","Load the model in 8-bit or 4-bit using bitsandbytes (QLoRA)\n","\n","This reduces memory usage from 14GB → 3–5GB."],"metadata":{"id":"aMFQlhedyeb9"}},{"cell_type":"code","source":["!pip install bitsandbytes accelerate transformers peft\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8D90aKYjtp3f","executionInfo":{"status":"ok","timestamp":1764624095053,"user_tz":-60,"elapsed":18920,"user":{"displayName":"Asmae Misbah","userId":"03840885929360177687"}},"outputId":"5502e044-8c21-4c63-c3f4-ebeb87ed3ad0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n","Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n","Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n","Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.48.2\n"]}]},{"cell_type":"code","source":["!pip install --upgrade transformers datasets accelerate bitsandbytes peft\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WS_xE4TvzAeW","outputId":"7e2b7aaf-51b7-4552-9f5b-1f18a477f6ee","executionInfo":{"status":"ok","timestamp":1764624581740,"user_tz":-60,"elapsed":9340,"user":{"displayName":"Asmae Misbah","userId":"03840885929360177687"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM\n","from peft import LoraConfig, get_peft_model\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    target_modules=[\"q\", \"v\"],  # T5 attention modules\n","    bias=\"none\",\n","    task_type=\"SEQ_2_SEQ_LM\"\n",")\n","\n","model = get_peft_model(model, lora_config)\n","model.print_trainable_parameters()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1TX0iiTRNbMW","executionInfo":{"status":"ok","timestamp":1764514146937,"user_tz":-60,"elapsed":2977,"user":{"displayName":"Asmae Misbah","userId":"03840885929360177687"}},"outputId":"23c59136-af39-4bd9-e1a9-971f2138437e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 4,718,592 || all params: 787,868,672 || trainable%: 0.5989\n"]}]},{"cell_type":"markdown","metadata":{"id":"2b00bcb6"},"source":["### Cell _yQLTzN4MxBu: Install Libraries\n","\n","This cell installs the necessary Python libraries for natural language processing and model training:\n","\n","- `transformers`: Provides pre-trained models, tokenizers, and utilities for NLP tasks.\n","- `accelerate`: Helps in training PyTorch models on various hardware setups, especially for distributed training and mixed precision.\n","- `datasets`: Offers tools to easily load, process, and share datasets for machine learning.\n","- `peft`: Parameter-Efficient Fine-Tuning library, used for efficiently adapting large pre-trained models to downstream tasks with minimal overhead."]},{"cell_type":"markdown","metadata":{"id":"3af74493"},"source":["### Cell _j4fd9i2NJeo: Load Datasets\n","\n","This cell loads the training, validation, and test datasets from CSV files into `Dataset` objects using the `load_dataset` function from the `datasets` library. These datasets are intended for a grammar correction task, with 'source' representing the incorrect sentence and 'target' representing the correct sentence."]},{"cell_type":"markdown","metadata":{"id":"cca51c39"},"source":["### Cell _XFCKupDsrXH: Define Preprocessing Function\n","\n","This cell defines a `preprocess` function that takes a batch of data (source and target sentences) and prepares it for the T5 model:\n","\n","1. **Prefix Addition**: It adds the prefix `\"gec: \"` to each source sentence. This prefix is often used with T5 models to indicate the specific task (in this case, Grammar Error Correction - GEC).\n","2. **Tokenization**: It tokenizes both the input (source) and target (label) sentences using the loaded T5 tokenizer.\n","   - `max_length=128`: Ensures all sequences are padded or truncated to a maximum length of 128 tokens.\n","   - `truncation=True`: Truncates sequences longer than `max_length`.\n","   - `padding=\"max_length\"`: Pads shorter sequences to `max_length`.\n","3. **Label Masking**: For the labels, it replaces padding tokens (`tokenizer.pad_token_id`) with `-100`. This is a standard practice in Hugging Face `Trainer` to make sure these padded tokens are ignored in the loss calculation."]},{"cell_type":"markdown","metadata":{"id":"4a7d98c9"},"source":["### Cell Fie6yoANsaNv: Apply Preprocessing\n","\n","This cell applies the `preprocess` function to the `train_dataset`, `valid_dataset`, and `test_dataset` using the `map` method. This transforms the raw text data into tokenized numerical inputs and labels suitable for model training. The `remove_columns` argument ensures that the original 'source' and 'target' text columns are removed, keeping only the tokenized inputs and labels."]},{"cell_type":"markdown","metadata":{"id":"49d0e3ab"},"source":["### Cell KLXaibyZtGPJ: Set Dataset Format\n","\n","This cell sets the format of the `train_dataset`, `valid_dataset`, and `test_dataset` to `\"torch\"`. This is important for ensuring that the datasets return PyTorch tensors, which are required for training with PyTorch and the Hugging Face `Trainer`."]},{"cell_type":"markdown","metadata":{"id":"863561d1"},"source":["### Cell 46mMRJtiNQrg: Load Tokenizer and Model\n","\n","This cell loads the pre-trained T5 tokenizer (`T5TokenizerFast`) and the T5 model for conditional generation (`T5ForConditionalGeneration`) from the specified Hugging Face model hub path (`\"gotutiyan/gec-t5-large-clang8\"`). It also configures the model's `pad_token_id` to match the tokenizer's and sets `use_cache` to `False`, which can sometimes help with memory usage during training."]},{"cell_type":"markdown","metadata":{"id":"07763d6f"},"source":["### Cell uMzE5wxytCap: Display Example from Training Dataset\n","\n","This cell displays the first example from the `train_dataset` after preprocessing. This allows you to inspect the tokenized `input_ids`, `attention_mask`, and `labels` to verify that the preprocessing step worked as expected."]},{"cell_type":"markdown","metadata":{"id":"2b970323"},"source":["### Cell H5huMEg8tg2E: Configure Training Arguments\n","\n","This cell defines the `TrainingArguments` for the `Trainer`. These arguments specify various aspects of the training process, including:\n","\n","- `output_dir`: Directory to save model checkpoints.\n","- `logging_strategy`, `save_strategy`, `eval_strategy`: Strategies for logging, saving, and evaluating (set to 'epoch').\n","- `learning_rate`: The initial learning rate.\n","- `per_device_train_batch_size`, `per_device_eval_batch_size`: Batch sizes for training and evaluation.\n","- `gradient_accumulation_steps`: Number of steps to accumulate gradients before performing a backward/update pass.\n","- `num_train_epochs`: Total number of training epochs.\n","- `weight_decay`: L2 regularization.\n","- `fp16=True`: Enables mixed-precision training (using float16) to reduce memory usage and speed up training.\n","- `report_to=\"none\"`: Disables reporting to external tools like Weights & Biases.\n","\n","It also enables `gradient_checkpointing` on the model, which can further reduce memory consumption at the cost of slightly slower training."]},{"cell_type":"markdown","metadata":{"id":"206200ad"},"source":["### Cell RzsGlg1LtjKi: Initialize and Train the Model (OOM Error)\n","\n","This cell attempts to initialize the Hugging Face `Trainer` with the loaded model, training arguments, and datasets, and then starts the training process using `trainer.train()`.\n","\n","**Error**: This cell resulted in an `OutOfMemoryError`. This indicates that the `T5ForConditionalGeneration` model, being a large model (`t5-large`), consumed too much GPU memory when loaded in full precision, even with `gradient_checkpointing` enabled. The error message explicitly states that the GPU has very little free memory, and the process is already using almost all of it."]},{"cell_type":"markdown","metadata":{"id":"130ddfc2"},"source":["### Cell t_kaorRIxW9R: Explanation of Out-of-Memory (OOM) Error\n","\n","This text cell clearly explains why the previous training attempt failed: the T5-Large model, in its full precision (32-bit floating point) form, is too big for the available 15GB GPU memory. The model itself, when loaded, consumes most of the GPU's capacity, leading to an immediate Out-of-Memory error even before actual training steps begin."]},{"cell_type":"markdown","metadata":{"id":"fa5b7a69"},"source":["### Cell aMFQlhedyeb9: Solution for OOM Error - Quantization (QLoRA)\n","\n","This text cell proposes the solution to the OOM issue: loading the model in a quantized format (8-bit or 4-bit) using techniques like QLoRA (Quantized Low-Rank Adaptation). Quantization significantly reduces the memory footprint of the model from around 14GB to 3-5GB, making it feasible to train on GPUs with limited memory like the one available."]},{"cell_type":"markdown","metadata":{"id":"5b22dfb2"},"source":["### Cell 8D90aKYjtp3f: Install `bitsandbytes`\n","\n","This cell installs the `bitsandbytes` library. This library is crucial for enabling 8-bit or 4-bit quantization, which is necessary to reduce the memory footprint of large language models like T5-Large, allowing them to fit into limited GPU memory."]},{"cell_type":"markdown","metadata":{"id":"c728d73a"},"source":["### Cell WS_xE4TvzAeW: Upgrade Libraries\n","\n","This cell upgrades several key libraries (`transformers`, `datasets`, `accelerate`, `bitsandbytes`, `peft`) to ensure that the latest versions with potentially critical bug fixes, performance improvements, and compatibility features (especially for quantization and PEFT) are in use."]},{"cell_type":"markdown","metadata":{"id":"476b0297"},"source":["### Cell 1TX0iiTRNbMW: Load Model with LoRA Configuration\n","\n","This cell implements the solution to the OOM error by loading the model with a LoRA (Low-Rank Adaptation) configuration:\n","\n","1. **`AutoModelForSeq2SeqLM.from_pretrained(model_name)`**: Loads the pre-trained T5 model. It's important that `bitsandbytes` is installed at this point, as `from_pretrained` can automatically detect and load the model in a quantized format if `load_in_8bit` or `load_in_4bit` arguments are passed (which are typically handled by `accelerate` or `peft` integration during fine-tuning).\n","2. **`LoraConfig`**: Defines the LoRA parameters:\n","   - `r=16`: The rank of the update matrices, controlling the number of trainable parameters.\n","   - `lora_alpha=32`: Scaling factor for LoRA updates.\n","   - `lora_dropout=0.05`: Dropout applied to the LoRA weights.\n","   - `target_modules=[\"q\", \"v\"]`: Specifies which modules in the T5 architecture (query and value projections in attention layers) will have LoRA layers added. This focuses fine-tuning on critical parts of the model.\n","   - `bias=\"none\"`: Specifies that bias terms are not included in LoRA layers.\n","   - `task_type=\"SEQ_2_SEQ_LM\"`: Indicates that this is a sequence-to-sequence language modeling task.\n","3. **`get_peft_model(model, lora_config)`**: Applies the LoRA configuration to the base model, creating a PEFT (Parameter-Efficient Fine-Tuning) model. This wraps the base model, adding small trainable LoRA adapters while keeping most of the base model's parameters frozen.\n","4. **`model.print_trainable_parameters()`**: Prints a summary of the trainable parameters. This shows that only a small percentage of the total model parameters are now trainable, drastically reducing memory and computational requirements during fine-tuning."]},{"cell_type":"markdown","metadata":{"id":"16413aff"},"source":["### Cell gwNgvYsgOdfg: Reconfigure Training Arguments\n","\n","This cell redefines the `TrainingArguments` after implementing LoRA. Key changes and important considerations:\n","\n","- **`per_device_train_batch_size=8`, `per_device_eval_batch_size=8`**: The batch sizes are increased significantly (from 1 to 8). With the reduced memory footprint from LoRA and quantization, larger batch sizes are now feasible, which can lead to faster training and potentially better gradient estimates.\n","- **`learning_rate=5e-5`**: The learning rate is adjusted.\n","- **`do_eval=True`**: Explicitly enables evaluation during training.\n","- **`logging_steps=100`**: Logs training progress every 100 steps.\n","- **`save_total_limit=2`**: Keeps only the best 2 model checkpoints.\n","\n","It's worth noting that the `evaluation_strategy` argument might have been removed or changed in newer `transformers` versions, as indicated by the comment `REMOVE evaluation_strategy (not supported in your version)`. The `do_eval=True` together with the `eval_strategy` (implicitly 'epoch' from previous cell or default if not specified) handles the evaluation."]},{"cell_type":"markdown","metadata":{"id":"66a8ebd9"},"source":["### Cell CxwjFZYzPaw_: Train and Evaluate Model with LoRA\n","\n","This cell initializes the `Trainer` with the LoRA-enabled model, the updated `TrainingArguments`, and the preprocessed datasets, then starts the training and evaluation process.\n","\n","1. **`trainer = Trainer(...)`**: Creates the `Trainer` instance. It correctly uses the `tokenizer` parameter, although a warning about its deprecation is noted in the output.\n","2. **`trainer.train()`**: Begins the fine-tuning process of the LoRA adapters.\n","3. **`trainer.evaluate()`**: After training, this explicitly runs an evaluation on the `eval_dataset` to get final performance metrics (in this case, `eval_loss`). The output `{'eval_loss': nan}` suggests there might be an issue during evaluation, possibly due to all labels being masked or other numerical instabilities, which would need further investigation."]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./gec_en_finetuned\",\n","    do_eval=True,\n","    # REMOVE evaluation_strategy (not supported in your version)\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=4,\n","    weight_decay=0.01,\n","    logging_steps=100,\n","    fp16=True,\n","    save_total_limit=2,\n","    report_to=\"none\"\n",")"],"metadata":{"id":"gwNgvYsgOdfg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset,\n","    tokenizer=tokenizer\n",")\n","\n","trainer.train()\n","\n","# manual eval\n","trainer.evaluate()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CxwjFZYzPaw_","executionInfo":{"status":"ok","timestamp":1764524967102,"user_tz":-60,"elapsed":10777068,"user":{"displayName":"Asmae Misbah","userId":"03840885929360177687"}},"outputId":"4845599f-2342-423b-f376-c7200e819a88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-910497408.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='19480' max='19480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [19480/19480 2:57:13, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18400</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18600</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18700</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18800</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18900</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>19100</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>19200</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>19300</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>19400</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='609' max='609' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [609/609 02:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': nan,\n"," 'eval_runtime': 124.5267,\n"," 'eval_samples_per_second': 39.108,\n"," 'eval_steps_per_second': 4.891,\n"," 'epoch': 4.0}"]},"metadata":{},"execution_count":10}]}]}