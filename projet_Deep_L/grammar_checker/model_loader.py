import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

MODEL_NAME = "prithivida/grammar_error_correcter_v1"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print("ðŸ”„ Chargement du modÃ¨le T5...")

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)

print("âœ… ModÃ¨le chargÃ© avec succÃ¨s !")
